<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Week 5 #  Topic: The Deep Metric Learning Family in Self-Supervised Learning
Keynote Speaker: Xinyao Li, Yiming Zhang, Shengqi Fang
Time: Jul 20, 19:30 - 21:30 pm
Venue: Lecture Hall 3, 302 (SUSTech)
Online Link: TencentMeeting
Compendium #  I. Contrastive Predictive Coding：
 Introduce Contrastive Predictive Coding, which learns self-supervised representations by predicting the future in latent space by using powerful autoregressive models. Introduce the concept of InfoNCE loss, which is a widely used loss function."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content><meta property="og:description" content="Week 5 #  Topic: The Deep Metric Learning Family in Self-Supervised Learning
Keynote Speaker: Xinyao Li, Yiming Zhang, Shengqi Fang
Time: Jul 20, 19:30 - 21:30 pm
Venue: Lecture Hall 3, 302 (SUSTech)
Online Link: TencentMeeting
Compendium #  I. Contrastive Predictive Coding：
 Introduce Contrastive Predictive Coding, which learns self-supervised representations by predicting the future in latent space by using powerful autoregressive models. Introduce the concept of InfoNCE loss, which is a widely used loss function."><meta property="og:type" content="article"><meta property="og:url" content="https://niusj03.github.io/23summer/docs/topics/week5/"><meta property="article:section" content="docs"><title>Week5 | 23 Summer Study</title><link rel=manifest href=/23summer/manifest.json><link rel=icon href=/23summer/favicon.png type=image/x-icon><link rel=stylesheet href=/23summer/book.min.33a48f5432973b8ff9a82679d9e45d67f2c15d4399bd2829269455cfe390b5e8.css integrity="sha256-M6SPVDKXO4/5qCZ52eRdZ/LBXUOZvSgpJpRVz+OQteg=" crossorigin=anonymous><script defer src=/23summer/flexsearch.min.js></script>
<script defer src=/23summer/en.search.min.d8921074c9209c7ad6a05de7acf3f7efc197fb4be143e560c149c7d4e9619663.js integrity="sha256-2JIQdMkgnHrWoF3nrPP378GX+0vhQ+VgwUnH1OlhlmM=" crossorigin=anonymous></script>
<script defer src=/23summer/sw.min.e333349655ab7baad14b3d2ed0333503afc9a1297b9c4c9bc81b88a385502a47.js integrity="sha256-4zM0llWre6rRSz0u0DM1A6/JoSl7nEybyBuIo4VQKkc=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/23summer/><span>23 Summer Study</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/23summer/docs/acknowledge/>Acknowledgement</a></li><li><a href=/23summer/docs/introduction/>Introduction</a></li><li><a href=/23summer/docs/schedule/>Schedule</a></li><li class=book-section-flat><span>Topics</span><ul><li><a href=/23summer/docs/topics/week1/>Week1</a></li><li><a href=/23summer/docs/topics/week2/>Week2</a></li><li><a href=/23summer/docs/topics/week3/>Week3</a></li><li><a href=/23summer/docs/topics/week4/>Week4</a></li><li><a href=/23summer/docs/topics/week5/ class=active>Week5</a></li><li><a href=/23summer/docs/topics/week6/>Week6</a></li><li><a href=/23summer/docs/topics/week7/>Week7</a></li><li><a href=/23summer/docs/topics/week8/>Week8</a></li></ul></li></ul><ul><li><a href=https://github.com/niusj03/23summer target=_blank rel=noopener>Github</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/23summer/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Week5</strong>
<label for=toc-control><img src=/23summer/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#compendium>Compendium</a></li><li><a href=#material>Material</a></li><li><a href=#reference>Reference</a></li></ul></nav></aside></header><article class=markdown><h1 id=week-5>Week 5
<a class=anchor href=#week-5>#</a></h1><p>Topic: The Deep Metric Learning Family in Self-Supervised Learning</p><p>Keynote Speaker: Xinyao Li, Yiming Zhang, Shengqi Fang</p><p>Time: Jul 20, 19:30 - 21:30 pm</p><p>Venue: Lecture Hall 3, 302 (SUSTech)</p><p>Online Link:
<a href=https://sustech.meeting.tencent.com/dm/rzsV1UdvWHtp>TencentMeeting</a></p><h2 id=compendium>Compendium
<a class=anchor href=#compendium>#</a></h2><p>I. Contrastive Predictive Coding：</p><ul><li>Introduce Contrastive Predictive Coding, which learns self-supervised representations by predicting the future in latent space by using powerful autoregressive models.</li><li>Introduce the concept of InfoNCE loss, which is a widely used loss function.</li></ul><p>II. The Contrastive Loss Function</p><ul><li>Introduce the core ideas of Deep Metric Learning and discuss the shortcomings of traditional Metric Learning methods.</li><li>Discuss DrLIM (Dimensionality Reduction by Learning an Invariant Mapping).</li><li>Introduce Contrastive Loss and its spring model analogy: Attract-only spring and m-Repulse-only spring.</li><li>Show the experiments of DrLIM along with traditional Metric Learning methods.</li></ul><p>III. The Triplet Loss Function</p><ul><li>Introduce Triplet Loss: anchor, positive and negative; easy, hard and semi-hard triplets.</li><li>Discuss the importance of triplet selection and two methods: choosing semi-hard triplets (applied in FaceNet) and Batch Hard.</li></ul><p>VI. A brief review of SimCLR:</p><ul><li>Introduce structure of contrastive learning.</li><li>emphasize the importance of data augmentation(random cropping and color distortion).</li></ul><h2 id=material>Material
<a class=anchor href=#material>#</a></h2><p>Slides
<a href=https://nbviewer.org/github/niusj03/23summer/blob/master/content/docs/pdfs/Week5_Li.pdf>1</a>,
<a href=https://nbviewer.org/github/niusj03/23summer/blob/master/content/docs/pdfs/Week5_Fang.pdf>2</a> and
<a href=https://nbviewer.org/github/niusj03/23summer/blob/master/content/docs/pdfs/Week5_Zhang.pdf>3</a> for Deep Metric Learning Family from Xinyao Li, Shengqi Fang and Yiming Zhang.</p><h2 id=reference>Reference
<a class=anchor href=#reference>#</a></h2><ol><li><p>Balestriero, R et al.
<a href=https://arxiv.org/abs/2304.12210>A Cookbook of Self-supervised Learning</a></p></li><li><p>R Hadsell et al,
<a href=https://ieeexplore.ieee.org/document/1640964>Dimensionality Reduction by Learning an Invariant Mapping</a></p></li><li><p>F Schroff et al,
<a href=https://ieeexplore.ieee.org/document/7298682>FaceNet: A unified embedding for face recognition and clustering</a></p></li><li><p>A Hermans et al,
<a href=https://arxiv.org/abs/1703.07737>In Defense of the Triplet Loss for Person Re-Identification</a></p></li><li><p>J Goldberger et al，
<a href=https://proceedings.neurips.cc/paper/2004/file/42fe880812925e520249e808937738d2-Paper.pdf>Neighbourhood Components Analysis</a></p></li><li><p>K Sohn et al,
<a href=https://papers.nips.cc/paper/2016/file/6b180037abbebea991d8b1232f8a8ca9-Paper.pdf>Improved Deep Metric Learning with Multi-class N-pair Loss Objective</a></p></li><li><p>A Oord et al，
<a href=https://arxiv.org/abs/1807.03748>Representation Learning with Contrastive Predictive Coding</a></p></li><li><p>T Chen et al,
<a href=https://arxiv.org/abs/2002.05709>A Simple Framework for Contrastive Learning of Visual Representations</a></p></li><li><p>A Dosovitskiy et al,
<a href=http://arxiv.org/abs/1406.6909>Discriminative Unsupervised Feature Learning with Convolutional Neural</a></p></li><li><p>Z Wu et al,
<a href=http://arxiv.org/abs/1805.01978>Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination</a></p></li></ol></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(n){const e=window.getSelection(),t=document.createRange();t.selectNodeContents(n),e.removeAllRanges(),e.addRange(t)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#compendium>Compendium</a></li><li><a href=#material>Material</a></li><li><a href=#reference>Reference</a></li></ul></nav></div></aside></main></body></html>